#!/bin/bash

# Script pour t√©l√©charger les donn√©es GSOD et les uploader dans HDFS
# Usage: ./download_and_upload_to_hdfs.sh

set -e  # Arr√™t en cas d'erreur

echo "==========================================="
echo "T√©l√©chargement et Upload GSOD vers HDFS"
echo "==========================================="

# Configuration
YEARS=(2019 2020 2021 2022 2023)
BASE_URL="https://www.ncei.noaa.gov/data/global-summary-of-the-day/archive"
LOCAL_DIR="/tmp/gsod_data"
HDFS_DIR="/data/gsod"

# Cr√©er le r√©pertoire local temporaire
mkdir -p "$LOCAL_DIR"
cd "$LOCAL_DIR"

# Cr√©er le r√©pertoire HDFS
echo ""
echo "Cr√©ation du r√©pertoire HDFS: $HDFS_DIR"
docker exec -it namenode hdfs dfs -mkdir -p "$HDFS_DIR"

# T√©l√©charger et uploader chaque ann√©e
for YEAR in "${YEARS[@]}"; do
    echo ""
    echo "========================================="
    echo "Traitement de l'ann√©e: $YEAR"
    echo "========================================="
    
    TAR_FILE="${YEAR}.tar.gz"
    EXTRACT_DIR="${YEAR}"
    
    # T√©l√©charger si n√©cessaire
    if [ ! -f "$TAR_FILE" ]; then
        echo "üì• T√©l√©chargement de $YEAR..."
        wget -q --show-progress "${BASE_URL}/${TAR_FILE}" -O "$TAR_FILE"
        echo "‚úì T√©l√©chargement termin√©"
    else
        echo "‚úì Archive $YEAR d√©j√† t√©l√©charg√©e"
    fi
    
    # Extraire
    if [ ! -d "$EXTRACT_DIR" ]; then
        echo "üì¶ Extraction de $TAR_FILE..."
        mkdir -p "$EXTRACT_DIR"
        tar -xzf "$TAR_FILE" -C "$EXTRACT_DIR"
        echo "‚úì Extraction termin√©e"
    else
        echo "‚úì Donn√©es $YEAR d√©j√† extraites"
    fi
    
    # Upload vers HDFS
    echo "‚òÅÔ∏è  Upload vers HDFS: ${HDFS_DIR}/${YEAR}/"
    docker exec -i namenode hdfs dfs -mkdir -p "${HDFS_DIR}/${YEAR}"
    
    # Copier tous les fichiers CSV vers HDFS
    # On copie depuis le host vers le conteneur puis vers HDFS
    docker cp "${LOCAL_DIR}/${EXTRACT_DIR}" namenode:/tmp/
    docker exec -i namenode bash -c "hdfs dfs -put -f /tmp/${EXTRACT_DIR}/*.csv ${HDFS_DIR}/${YEAR}/"
    docker exec -i namenode rm -rf "/tmp/${EXTRACT_DIR}"
    
    echo "‚úì Upload termin√© pour $YEAR"
    
    # V√©rifier l'upload
    echo "üìä V√©rification des fichiers dans HDFS:"
    docker exec -i namenode hdfs dfs -ls "${HDFS_DIR}/${YEAR}" | head -n 10
done

echo ""
echo "==========================================="
echo "‚úÖ PROCESSUS TERMIN√â AVEC SUCC√àS"
echo "==========================================="
echo ""
echo "üìÅ Structure HDFS cr√©√©e:"
docker exec -i namenode hdfs dfs -ls -R "$HDFS_DIR" | grep "^d"
echo ""
echo "üìä Statistiques:"
for YEAR in "${YEARS[@]}"; do
    COUNT=$(docker exec -i namenode hdfs dfs -ls "${HDFS_DIR}/${YEAR}" | grep -c "\.csv" || echo "0")
    echo "  - $YEAR: $COUNT fichiers CSV"
done
echo ""
echo "üéØ Les donn√©es sont maintenant disponibles dans HDFS √†: hdfs://namenode:9000${HDFS_DIR}"
echo ""
echo "üí° Pour nettoyer les fichiers locaux temporaires:"
echo "   rm -rf $LOCAL_DIR"
